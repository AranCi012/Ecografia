{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfd2bec7-373a-4909-a68b-8cb4dfd6c0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e57d29-eed2-4d85-8919-24aab890611a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np \n",
    "\n",
    "model=load_model('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37885486-2407-4e53-ad32-8796029d2c0e",
   "metadata": {},
   "source": [
    "- **Quantizzo modello**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b529e1-99e0-4d57-a74a-1255d139102a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Converti il modello in un modello TensorFlow Lite quantizzato\\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\\nquantized_tflite_model = converter.convert()\\n\\n# Salva il modello quantizzato su disco\\nwith open('/users/emanueleamato/Downloads/Esame Echo Emanuele /20240215/model_quantized.tflite', 'wb') as f:\\n    f.write(quantized_tflite_model)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Converti il modello in un modello TensorFlow Lite quantizzato\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_tflite_model = converter.convert()\n",
    "\n",
    "# Salva il modello quantizzato su disco\n",
    "with open('/users/emanueleamato/Downloads/Esame Echo Emanuele /20240215/model_quantized.tflite', 'wb') as f:\n",
    "    f.write(quantized_tflite_model)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2de3e2e-1ed8-4083-857e-a65e868b9d54",
   "metadata": {},
   "source": [
    "- **Real time Inference** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db3888ed-3b74-4a3c-9a0a-5f2932822685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Carica il modello TensorFlow Lite\n",
    "model = tf.lite.Interpreter(model_path=\"model_quantized.tflite\")\n",
    "model.allocate_tensors()\n",
    "\n",
    "# Definisci una funzione per preprocessare i frame\n",
    "def preprocess_frame(frame):\n",
    "    resized_frame = cv2.resize(frame, (224, 224))\n",
    "    normalized_frame = resized_frame / 255.0\n",
    "    preprocessed_frame = np.expand_dims(normalized_frame.astype(np.float32), axis=0) \n",
    "    return preprocessed_frame\n",
    "\n",
    "\n",
    "\n",
    "# Apri la sorgente video (ad esempio, una duplicazione dello schermo)\n",
    "video_capture = cv2.VideoCapture(0)  # Modifica il numero per utilizzare una sorgente video diversa\n",
    "\n",
    "while True:\n",
    "    # Leggi il frame dalla sorgente video\n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Preprocessa il frame\n",
    "    processed_frame = preprocess_frame(frame)\n",
    "\n",
    "    # Esegui l'inferenza sul frame\n",
    "    model.set_tensor(model.get_input_details()[0]['index'], processed_frame)\n",
    "    model.invoke()\n",
    "\n",
    "    # Ottieni l'output dell'inferenza\n",
    "    output_details = model.get_output_details()[0]\n",
    "    output_data = model.get_tensor(output_details['index'])\n",
    "\n",
    "    # Trova la classe predetta e la probabilità massima\n",
    "    predicted_class_index = np.argmax(output_data)\n",
    "    labels = [\"2CH\", \"4CH\"]  # Sostituisci con le tue etichette di classe\n",
    "    predicted_class_name = labels[predicted_class_index]\n",
    "    max_probability = np.max(output_data)\n",
    "\n",
    "    # Disegna il testo sul frame con il nome della classe predetta e la probabilità\n",
    "    text = f\"Class: {predicted_class_name}, Probability: {max_probability}\"\n",
    "    cv2.putText(frame, text, (25, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    # Mostra il frame con le previsioni\n",
    "    cv2.imshow('Frame', frame)\n",
    "    \n",
    "    # Esci se viene premuto il tasto 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Rilascia la cattura del video e chiudi le finestre\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e28d56a-b03b-451f-b068-98c52a378fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pyautogui \\nimport cv2\\nimport numpy as np\\nimport tensorflow as tf\\n\\n# Carica il modello TensorFlow Lite\\nmodel = tf.lite.Interpreter(model_path=\"model_quantized.tflite\")\\nmodel.allocate_tensors()\\n\\n# Definisci una funzione per preprocessare i frame\\ndef preprocess_frame(frame):\\n    resized_frame = cv2.resize(frame, (256, 256))\\n    normalized_frame = resized_frame / 255.0\\n    preprocessed_frame = np.expand_dims(normalized_frame.astype(np.float32), axis=0) \\n    return preprocessed_frame\\n\\n\\nwhile True:\\n    # Leggi il frame dalla sorgente video\\n    screenshot=pyautogui.screenshot(region=(1920,1080,1920,1080))\\n    frame=np.array(screenshot)\\n    preprocessed_frame=preprocess_frame(frame)\\n\\n    input_details=model.get_input_details()\\n    output_details=model.get_output_details()\\n    model.set_tensor(input_details[0][\\'index\\'],preprocessed_frame)\\n    model.invoke()\\n\\n    output_data=model.get_tensor(output_details[0][\\'index\\'])\\n    predicted_class_index = np.argmax(output_data)\\n    labels = [\"Good\", \"Medium\", \"Poor\"]  # Sostituisci con le tue etichette di classe\\n    predicted_class_name = labels[predicted_class_index]\\n    max_probability = np.max(output_data)\\n\\n    # Disegna il testo sul frame con il nome della classe predetta e la probabilità\\n    text = f\"Class: {predicted_class_name}, Probability: {max_probability}\"\\n    cv2.putText(frame, text, (25, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\\n    \\n    # Esci se viene premuto il tasto \\'q\\'\\n    if cv2.waitKey(1) & 0xFF == ord(\\'q\\'):\\n        break\\ncv2.destroyAllWindows()\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pyautogui \n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Carica il modello TensorFlow Lite\n",
    "model = tf.lite.Interpreter(model_path=\"model_quantized.tflite\")\n",
    "model.allocate_tensors()\n",
    "\n",
    "# Definisci una funzione per preprocessare i frame\n",
    "def preprocess_frame(frame):\n",
    "    resized_frame = cv2.resize(frame, (256, 256))\n",
    "    normalized_frame = resized_frame / 255.0\n",
    "    preprocessed_frame = np.expand_dims(normalized_frame.astype(np.float32), axis=0) \n",
    "    return preprocessed_frame\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Leggi il frame dalla sorgente video\n",
    "    screenshot=pyautogui.screenshot(region=(1920,1080,1920,1080))\n",
    "    frame=np.array(screenshot)\n",
    "    preprocessed_frame=preprocess_frame(frame)\n",
    "\n",
    "    input_details=model.get_input_details()\n",
    "    output_details=model.get_output_details()\n",
    "    model.set_tensor(input_details[0]['index'],preprocessed_frame)\n",
    "    model.invoke()\n",
    "\n",
    "    output_data=model.get_tensor(output_details[0]['index'])\n",
    "    predicted_class_index = np.argmax(output_data)\n",
    "    labels = [\"Good\", \"Medium\", \"Poor\"]  # Sostituisci con le tue etichette di classe\n",
    "    predicted_class_name = labels[predicted_class_index]\n",
    "    max_probability = np.max(output_data)\n",
    "\n",
    "    # Disegna il testo sul frame con il nome della classe predetta e la probabilità\n",
    "    text = f\"Class: {predicted_class_name}, Probability: {max_probability}\"\n",
    "    cv2.putText(frame, text, (25, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    # Esci se viene premuto il tasto 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1182252-7798-42cf-8cc8-6f59b0a3c61a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56d7709-37e9-4bdc-8891-09bc12265273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
