{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f2cd7c-28a7-4f30-9fbb-8cefb3ba0218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.8/dist-packages/torch/__init__.py')\n",
    "sys.path.append('/lustrehome/emanueleamato/.local/lib/python3.11/site-packages')\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f54bc2-b115-4d8e-96d2-8c556a1999aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Controllo dimensioni immagine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706e5cbd-1a6a-4500-84ee-09f804e43cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica l'immagine utilizzando Keras\n",
    "\n",
    "img_path = '###Load Image###' \n",
    "img = image.load_img(img_path)\n",
    "\n",
    "# Converti l'immagine in un array NumPy\n",
    "img_array = image.img_to_array(img)\n",
    "\n",
    "# Controlla il numero di canali dell'immagine\n",
    "num_channels = img_array.shape[-1]  # Assumendo che l'immagine sia nel formato (H, W, C) dopo la conversione\n",
    "print(\"Numero di canali dell'immagine nel dataset:\", num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a10b232-abf8-4e43-8470-63cc01d1c725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcf16d5-d84a-4bd2-b8c2-dfcdb56b4b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def SimpleCNN():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Passo 1: Convoluzione -> Attivazione -> Dropout\n",
    "    model.add(Conv2D(8, (3, 3), strides=(1, 1), padding='same', input_shape=(64, 64, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # Passo 2: Convoluzione -> Attivazione -> Pooling\n",
    "    model.add(Conv2D(16, (3, 3), strides=(1, 1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "    \n",
    "    # Passo 3: Convoluzione -> Pooling\n",
    "    model.add(Conv2D(32, (3, 3), strides=(1, 1), padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "    \n",
    "    # Appiattimento (flatten)\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Passo 4: Fully Connected Layer -> Attivazione\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # Passo 5: Fully Connected Layer (output layer)\n",
    "    model.add(Dense(2))  # Numero di classi\n",
    "    model.add(Activation('softmax'))  # Softmax per output di classificazione\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf9ade8-eedd-4c88-8965-6ff8e7828ed5",
   "metadata": {},
   "source": [
    "# Addestro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b6273f-c98b-4df1-8175-d53c890e1299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iperparametri\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "\n",
    "# Carica il dataset di immagini senza trasformazioni\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    '/lustrehome/emanueleamato/ViT_Test/Train',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse'  \n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    '/lustrehome/emanueleamato/ViT_Test/Test',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "# Verifica i dispositivi disponibili\n",
    "devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Devices:\", devices)\n",
    "\n",
    "# Verifica se sono disponibili dispositivi GPU\n",
    "#if devices:\n",
    " #   tf.config.experimental.set_visible_devices(devices[0], 'GPU')\n",
    "\n",
    "# Definisci il modello\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Compila il modello\n",
    "model.compile(optimizer=Adam(lr=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callback per il salvataggio del modello durante l'addestramento\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor=\"val_accuracy\", save_best_only=True)\n",
    "\n",
    "# Addestra il modello\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=len(train_generator),\n",
    "                    epochs=num_epochs,\n",
    "                    validation_data=test_generator,\n",
    "                    validation_steps=len(test_generator),\n",
    "                    callbacks=[checkpoint],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0a0bf9-aa04-426e-b9d8-055b0ae88cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
